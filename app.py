
import streamlit as st
import tensorflow as tf
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image
import numpy as np
import plotly.graph_objects as go
import cv2
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Flatten
from tensorflow.keras.optimizers import Adamax
from tensorflow.keras.metrics import Precision, Recall
import google.generativeai as genai
from google.colab import userdata
import PIL.Image
import os
from google.colab import userdata
from dotenv import load_dotenv
load_dotenv()

genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))

#Display silency map in app
output_dir = 'saliency_maps'
os.makedirs(output_dir, exist_ok=True)


#Generate explanation using Gemini API
def generate_explanation(img_path, model_prediction, confidence):
  prompt =f"""You are an expert neuroscientist adn neurologist with a PhD and more that 20 years of experience in the field. You are tasked with explaining a saliency map of a brain tumo MRI scan.
            The saliency map was generated by a deep learning model that was trained to classify brain tumors as either glioma ,meningioma, pituitary, or no tumor

            The saliency map highlights the regions of the image that the machine learning model is focusing on to make teh predictions.

            The deep learning model predicted the image to be of class '{model_prediction}' with a confidence of {confidence * 100}%.

            In your response:
            - Explain what regiosn of the brain the model is focusing on, based on the saliency map. Refer to the regions highlighted in the light cyan, those are where the model is focusing on.
            - Explain  possible reasons why the mdoel made the prediction it did.
            - Don't mention anything like 'The saliency map highlights teh regions the model is focusing on, which are in light cyan'
            - Keep your explanation to 4 to 5 setences max.
            - Make sure any one on teh ages from 15 to any older can understant the explanation you provide. However don't forget to keep you proffesionalism in you explanation.

            Let's think step by step about this. Verify step by step."""

  img = PIL.Image.open(img_path)

  model = genai.GenerativeModel(model_name="gemini-1.5-flash")
  response = model.generate_content([prompt, img])

  return response.text

#Col 2 image with saliency map
def generate_saliency_map(model, img_array, class_index, img_size):
  with tf.GradientTape() as tape:
    img_tensor = tf.convert_to_tensor(img_array)
    tape.watch(img_tensor)
    predictions = model(img_tensor)
    target_class = predictions[:, class_index]

  gradients = tape.gradient(target_class, img_tensor)
  gradients = tf.math.abs(gradients)
  gradients = tf.reduce_max(gradients, axis=-1)
  gradients = gradients.numpy().squeeze()

  #Resizig gradients to match original image size
  gradients = cv2.resize(gradients, img_size)

  #Create a circular mask for the brain area
  center = (gradients.shape[0] // 2, gradients.shape[1] // 2)
  radius = min(center[0], center[1]) - 10
  y, x = np.ogrid[:gradients.shape[0], :gradients.shape[1]]
  mask = (x - center[0]**2 + (y - center[1])**2 <= radius**2)

  #Apply mask to gradients
  gradients = gradients * mask

  #Normalize only the brain area
  brain_gradients = gradients[mask]
  if brain_gradients.max() > brain_gradients.min():
    brain_gradients = (brain_gradients - brain_gradients.min()) / (brain_gradients.max() - brain_gradients.min())
  gradients[mask] = brain_gradients

  #Apply a higher treshold
  threshold = np.percentile(gradients[mask], 80)
  gradients[gradients < threshold] = 0

  #Apply more aggresice smoothing
  gradients = cv2.GaussianBlur(gradients, (11, 11), 0)

  #Create a heatmap overlay with enchanced contrast
  heatmap = cv2.applyColorMap(np.uint8(255 * gradients), cv2.COLORMAP_JET)
  heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)

  #Resize heatmap to match original image size
  heatmap = cv2.resize(heatmap, img_size)

  #Superimpose the heatmap on original image with increased opacity
  original_img = image.img_to_array(img)
  superimposed_img = heatmap * 0.7 + original_img * 0.3
  superimposed_img = superimposed_img.astype(np.uint8)

  img_path = os.path.join(output_dir, uploaded_file.name)
  with open(img_path, "wb") as f:
    f.write(uploaded_file.getbuffer())

  silency_map_path = f'saliency_maps/{uploaded_file.name}'

  #save the saliency map
  cv2.imwrite(silency_map_path, cv2.cvtColor(superimposed_img, cv2.COLOR_RGB2BGR))

  return superimposed_img

#Helper load RESNET
def load_resnet_model(model_path):
    img_shape = (299, 299, 3)  # Input shape for ResNet50
    base_model = tf.keras.applications.ResNet50(
        include_top=False,  # Exclude the top fully connected layers
        weights="imagenet",  # Pretrained weights
        input_shape=img_shape,
        pooling='max'  # Global max pooling
    )

    # Build the custom model
    model = Sequential([
        base_model,
        Flatten(),
        Dropout(rate=0.3),
        Dense(128, activation='relu'),
        Dropout(rate=0.25),
        Dense(4, activation='softmax')  # 4 neurons for 4 classes
    ])

    # Compile the model with Adamax and custom metrics
    model.compile(
        optimizer=Adamax(learning_rate=0.001),
        loss='categorical_crossentropy',
        metrics=['accuracy', Precision(), Recall()]
    )

    # Load weights
    model.load_weights(model_path)

    return model


#Helper custom function to load Xcpetion model
def load_xception_model(model_path):
  img_shape = (299, 299, 3)
  base_model = tf.keras.applications.Xception(include_top=False, weights="imagenet", input_shape=img_shape, pooling='max')

  model = Sequential([
      base_model,
      Flatten(),
      Dropout(rate=0.3),
      Dense(128, activation='relu'),
      Dropout(rate=0.25),
      Dense(4, activation='softmax')
  ])

  model.build((None,) + img_shape)

  #Compilation of model
  model.compile(Adamax(learning_rate=0.001,
                       loss='categorical_crossentropy',
                       metrics=['accuracy', Precision(), Recall()]))
  model.load_weights(model_path)

  return model

#Streamlit UI and interaction components starting point:
st.title("Brain Tumor Classification")

st.write("Upload an image of brain MRI scan to classify")

uploaded_file = st.file_uploader("Choose an image...", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
  selected_model = st.radio(
      "Selected Model",
      ("Transfer Learning - Xception", "Custom CNN", "Transfer Learning - ResNet50")
  )

  if selected_model == "Transfer Learning -Xception":
    model = load_xception_model('/content/xception_mmodel.weights.h5')
    img_size = (299, 299)

  elif selected_model == "Transfer Learning - ResNet50":
    model = load_resnet_model('/content/resnet_model.weights.h5')
    img_size = (299, 299)

  else:
    model = load_model('/content/cnn_model_ff.h5')
    img_size = (224, 224)

  #Generate prediction of the model, when and img is uploaded and type of model is selected
  labels = ['Glioma', 'Meningioma', 'No tumor', 'Pituitary']
  img = image.load_img(uploaded_file, target_size=img_size)
  img_array = image.img_to_array(img)
  img_array = np.expand_dims(img_array, axis=0)
  img_array /= 255.0

  prediction = model.predict(img_array)

  #Get the true probabilities for the class with the highest ones
  class_index = np.argmax(prediction[0])
  result = labels[class_index]

  st.write(f"Predicted Class: {result}")
  st.write("Predictions:")
  for label, prob in zip(labels, prediction[0]):
    st.write(f"{label}: {prob:.4f}")

  saliency_map = generate_saliency_map(model, img_array, class_index, img_size)

  col1, col2 = st.columns(2)
  with col1:
    st.image(uploaded_file, caption='Uploaded Image', use_container_width=True)
  with col2:
    st.image(saliency_map, caption='Saliency Map', use_container_width=True)



  #Classificaion report part
  results_container = st.container()
  results_container = st.container()
  results_container.markdown(
      f"""
      <div style="
  background: linear-gradient(135deg, #1e3c72, #2a5298);
  color: #ffffff;
  padding: 30px;
  border-radius: 15px;
  box-shadow: 0 8px 20px rgba(0, 0, 0, 0.2);
  text-align: center;
  transition: transform 0.3s ease;
  transform-origin: center;
  font-family: Arial, sans-serif;"
  onmouseover="this.style.transform='scale(1.05)';"
  onmouseout="this.style.transform='scale(1)';">
  <div style="
    display: flex;
    flex-direction: column;
    align-items: center;">
    <!-- Icon or Graphic -->
    <div style="
      margin-bottom: 15px;
      width: 60px;
      height: 60px;
      border-radius: 50%;
      background: radial-gradient(circle, #ffffff, #ffde03);
      display: flex;
      align-items: center;
      justify-content: center;
      box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);">
      <span style="font-size: 24px; font-weight: bold; color: #1e3c72;">âš¡</span>
    </div>
    <!-- Title -->
    <h3 style="
      margin-bottom: 10px;
      font-size: 22px;
      text-transform: uppercase;
      letter-spacing: 2px;
      font-weight: 600;">Confidence</h3>
    <!-- Percentage Value -->
    <p style="
      font-size: 48px;
      font-weight: 900;
      color: #FFD700;
      margin: 0;">
      {prediction[0][class_index]:.4%}
    </p>
  </div>
</div>

      """,
      unsafe_allow_html=True
  )

  #Prepare data for plotly chart
  probabilities = prediction[0]
  sorted_indices = np.argsort(probabilities)[::-1]
  sorted_labels = [labels[i] for i in sorted_indices]
  sorted_probabilities = probabilities[sorted_indices]

  #Create teh plotly bar chart
  fig = go.Figure(go.Bar(
      x=sorted_probabilities,
      y=sorted_labels,
      orientation='h',
      marker_color=['red' if label == result else 'blue' for label in sorted_labels]
  ))

  #Customization of chart
  fig.update_layout(
      title='Probabilities for each class',
      xaxis_title='Probability',
      yaxis_title='Class',
      height=400,
      width=600,
      yaxis=dict(autorange='reversed')
  )

  #Add value to the labels of the bars
  for i, prob in enumerate(sorted_probabilities):
    fig.add_annotation(
        x=prob,
        y=i,
        text=f'{prob:.4f}',
        showarrow=False,
        xanchor='left',
        xshift=5
    )

  st.plotly_chart(fig)

  saliency_map_path = f'saliency_maps/{uploaded_file.name}'
  explanation = generate_explanation(saliency_map_path, result, prediction[0][class_index])

  #Explanation report
  st.write("## Explanation")
  st.write(explanation)
